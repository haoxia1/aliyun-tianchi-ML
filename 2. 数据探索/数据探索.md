# Note

[toc]

## 二、数据探索

### 1. 理论知识

#### 1.1 变量识别

- 识别输入变量/特征(predictor)与输出变量/标签(target)
- 识别数据类型及判断时连续型变量还是类别型变量

>- 连续型数据：在一定区间内可以任意取值的变量叫连续变量，其数值是连续不断的。例如，生产零件的规格尺寸，人体测量的身高、体重等。可视化这类数据的图表主要有箱形图和直方图。
>- 离散型数据：数值只能用自然数或整数单位计算的则为离散变量。例如，企业个数，职工人数，设备台数等，只能按计量单位数计数。大多数图表可视化的都是这类数据，比如柱状图、折线图等。

#### 1.2 变量分析

- **单变量分析**
  - 对于**连续型变量**，需统计数据的中心分布趋势(central tendency)和变量的分布(dispersion)
    - 中心分布趋势:平均值$mean$，中位数$median$，众数$mode$，最小值$min$，最大值$max$
    - 变量分布:区间$range$，四分位数$quartile$，四分位间距$IQR$(3/4处减去1/4处)，方差$variance$，标准差$standard deviation$，峰态$kurtosis$
  - 对于**类别型变量**，使用频次或频率(占比)表示每类的分布情况

- **双变量分析**
  - **连续型与连续型**
    - 绘制**散点图**：反映变量之间的关系是线性还是非线性
    ![图 1](/images/3431ca1c91c271cab5c9ec69db7957a09ed5d2d06c77bd36519ba58b7ec84634.png)  
    - 计算**相关性**：散点图只能直观反映双变量的关系，但不能说明关系的强弱，可通过相关性系数对变量之间的关系进行量化分析。
   $$Correlation = \frac{Covariance(X,Y)}{\sqrt{Var(X)*Var(Y)}}$$
      - `np.corrcoef(X, Y)`;相关性系数=-1时，表示强负线性相关，=1表示强正线性相关，=0表示不相关;一般来说$0-0.09$为没有相关性，$0.1-0.3$位弱相关，$0.3-0.5$为中等相关，$0.5-1.0$为强相关。
  - **类别型与类别型**
    - 双向表
    - 堆叠柱状图
    - 卡方检验：统计样本的实际观测值与理论推断值之间的偏离程度，卡方值越大，二者偏离程度越大。

      ```python
      import numpy as np
      from sklearn.datasets import load_iris
      # 选择出前k个与标签最相关的特征
      from sklearn.feature_selection import SelectKBest 
      from sklearn.feature_selection import chi2 # 卡方检验
      iris = load_iris()
      X, y = iris.data, iris.target
      chiValues = chi2(X, y)
      X_new = SelectKBest(chi2,k=2).fit_transform(X, y)
      # selectKbest选出前k个与标签y最相关的特征 fit_transform还不懂
      ```

  - **类别型与连续型**
    - 小提琴图$violin\ plot$：分析类变变量在不同类别时，另一个连续变量的分布情况。

#### 1.3 缺失值处理

缺失值处理办法

- **删除**
  - 成列删除，即删去该样本，简单，但你和能力降低
  - 成对删除，即删除对应的缺失值，保留更多的样本数，不同特征使用大小不同的样本
- **平均值、众数、中值填充**（最常用）
- **预测模型填充**
  - 通过建立预测模型天不缺失值，将训练集分为两份，没有缺失值的那份作为训练集，有缺失值的作为测试集，那么模型预测目标即为缺失值。

#### 1.4 异常值处理

异常值：远远偏离整个样本总体的观测值。
可能产生的原因：数据输入误差、测量误差、实验误差、人为有意异常值、数据处理误差、采样误差等。

##### 检测异常值

- 可视化方法
  - 箱线图（不在$-1.5IQR-1.5IQR$之间的样本点(即在上下边缘之外)被认为是异常值）、直方图、散点图

##### 处理方法

- 删除
- 转换：如取对数会减轻由极值引起的变化
- 使用平均值、中值等填充
- 区别对待：若存在大量异常值，则异常值分一组，非异常值分一组

#### 1.5 变量转换

当某变量的取值分布不平均是，需对变量的取值空间进行转换，使其分布落在合理的空间内。
![图 1](/images/e1a0959cc1cbdee944774da95f5dbcc64ba2c6ffa7b6b8cd2728b32dbae510d6.png)  

变量转换的方法：

- 缩放比例或标准化：因为数据具有不同的缩放比例，不会更改变量的分布。
- 非线性转换为线性：线性关系更易理解，常用对数变换
- 使倾斜分布对称：取平方根和立方根或对数指数等
- 变量分组

#### 1.6 新变量生成

基于现有变量生成新变量，可能新变量与目标变量有更好的相关性。如将Date(dd-mm-yy)拆分成年、月、日、周等。
方法：

- 创建派生变量
- 创建哑变量：将类别型变量转换为数值型变量；如将Gender变为isMale和isFemale两个数值型(0,1)。

#### 1.7 各种图

直方图($histogram$)：表示数据的分布情况的图表；横轴表示数据样本，纵轴表示数据分布情况；
Q-Q图：对比参照数据的分位数和正态分布的分位数的图，如果数据符合正态分布，则所有的店都落在直线上；

### 2. 赛题数据探索实操

1. 导入工具包
   1. `numpy,pandas,matplotlib,seaborn`
2. 读取数据
   1. `pd.read_csv()`
3. 查看数据
   1. `df.info(), df.describe(), df.head()`
4. 可视化数据分布
   1. 箱形图`sns.boxplot()`观察一下异常值
   2. 获取异常数据并画图
   3. 直方图和Q-Q图`sns.distplot(), stats.probplot()`观察一下分布是否近似与正态分布
   4. KDE分布图(核密度估计)`sns.kdeplot()` KDE是直方图的加窗平滑；用以对比训练集和测试集中特征变量的分布情况，发现不一致的特征变量。
   5. 线性回归关系图`sns.regplot()`观察特征变量与target变量之间的线性回归关系
5. 查看特征变量的相关性
   1. 计算相关性系数`df.corr()`
   2. 画相关性热力图`sns.heatmap()`
   3. 依据相关性系数筛选特征变量
   4. $Box-Cox$变换
